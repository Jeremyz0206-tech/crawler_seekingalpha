
# ğŸ•·ï¸ ä½¿ç”¨ Playwright çˆ¬å– SeekingAlpha æ–°é—»æ ‡é¢˜ï¼ˆmacOS æ¡Œé¢ä¿å­˜ç‰ˆï¼‰

## ğŸ“Œ æ•™ç¨‹ç›®å½•

1. [ç¯å¢ƒå®‰è£…](#ç¯å¢ƒå®‰è£…)
2. [çˆ¬å–ç›®æ ‡](#çˆ¬å–ç›®æ ‡)
3. [å®Œæ•´è„šæœ¬ï¼ˆä¿å­˜åˆ°æ¡Œé¢ï¼‰](#å®Œæ•´è„šæœ¬ä¿å­˜åˆ°æ¡Œé¢)
4. [è¾“å‡ºæ•ˆæœ](#è¾“å‡ºæ•ˆæœ)
5. [å¯é€‰å¢å¼º](#å¯é€‰å¢å¼º)

---

## âœ… ç¯å¢ƒå®‰è£…

```bash
pip install playwright nest_asyncio pandas tqdm
playwright install
```

---

## ğŸ¯ çˆ¬å–ç›®æ ‡

ä» SeekingAlpha ç½‘ç«™çˆ¬å–å¦‚ä¸‹è‚¡ç¥¨çš„æ–°é—»æ ‡é¢˜å’Œé“¾æ¥ï¼š

- `https://seekingalpha.com/symbol/AAPL/news`
- `https://seekingalpha.com/symbol/TSLA/news`
- `https://seekingalpha.com/symbol/NVDA/news`

---

## ğŸ’» å®Œæ•´è„šæœ¬ï¼ˆä¿å­˜åˆ°æ¡Œé¢ï¼‰

```python
import pandas as pd
from tqdm.asyncio import tqdm
import asyncio
from playwright.async_api import async_playwright
import nest_asyncio
import os

nest_asyncio.apply()

desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
symbols = ["AAPL", "TSLA", "NVDA"]

async def scrape_symbol(symbol):
    print(f"\nğŸ” Scraping {symbol}...")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()

        url = f"https://seekingalpha.com/symbol/{symbol}/news"
        await page.goto(url, timeout=60000)

        try:
            await page.wait_for_selector('a[data-test-id="post-list-item-title"]', timeout=15000)
        except:
            print(f"âŒ Failed to load articles for {symbol}")
            await browser.close()
            return

        article_elements = await page.query_selector_all('a[data-test-id="post-list-item-title"]')
        data = []
        for tag in article_elements:
            title = await tag.inner_text()
            href = await tag.get_attribute("href")
            full_url = "https://seekingalpha.com" + href
            data.append({"title": title.strip(), "url": full_url})

        await browser.close()

        if data:
            df = pd.DataFrame(data)
            filename = os.path.join(desktop_path, f"{symbol.lower()}_news_playwright.csv")
            df.to_csv(filename, index=False, encoding="utf-8-sig")
            print(f"âœ… Saved {len(df)} articles to {filename}")
        else:
            print(f"âš ï¸ No news found for {symbol}")

# æ‰§è¡Œä»»åŠ¡
await asyncio.gather(*(scrape_symbol(symbol) for symbol in symbols))
```

---

## ğŸ“ è¾“å‡ºæ•ˆæœ

- åœ¨æ¡Œé¢ç”Ÿæˆï¼š
  - `aapl_news_playwright.csv`
  - `tsla_news_playwright.csv`
  - `nvda_news_playwright.csv`
- æ¯ä¸ªæ–‡ä»¶åŒ…æ‹¬æ–°é—»æ ‡é¢˜å’Œé“¾æ¥

---


